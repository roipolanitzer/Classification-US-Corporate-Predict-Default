{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression__ is a Machine Learning classification algorithm that is used to predict the probability of a categorical dependent variable. In logistic regression, the dependent variable is a binary variable that contains data coded as 1 (yes, success, etc.) or 0 (no, failure, etc.). In other words, the logistic regression model predicts P(Y=1) as a function of X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Binary logistic regression requires the dependent variable to be binary.\n",
    "2. For a binary regression, the factor level 1 of the dependent variable should represent the desired outcome.\n",
    "3. Only the meaningful variables should be included.\n",
    "4. The independent variables should be independent of each other. That is, the model should have little or no multicollinearity.\n",
    "5. The independent variables are linearly related to the log odds.\n",
    "6. Logistic regression requires quite large sample sizes.\n",
    "\n",
    "Keeping the above assumptions in mind, letâ€™s look at our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data comes from listed US corporates and consists of five ratios from the widely known Z-score developed by Altman (1968). \n",
    "WC/TA captures the short-term liquidity of a firm, RE/TA and EBIT/TA measure historic and current profitability, respectively. S/TA further proxies for the competitive situation of the company and ME/TL is a market-based measure of leverage. The classification goal is to predict whether a firm will default (1/0) (variable y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 6.0)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21553, 7)\n",
      "['Firm ID', 'WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA', 'y']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('US_Corporate_Default.csv')\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firm ID</th>\n",
       "      <th>WC/TA</th>\n",
       "      <th>RE/TA</th>\n",
       "      <th>EBIT/TA</th>\n",
       "      <th>ME/TL</th>\n",
       "      <th>S/TA</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.31</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>36</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>37</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>39</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Firm ID  WC/TA  RE/TA  EBIT/TA  ME/TL  S/TA  y\n",
       "0         1   0.50   0.31     0.04   0.96  0.33  0\n",
       "1         2   0.55   0.32     0.05   1.06  0.33  0\n",
       "2         3   0.45   0.23     0.03   0.80  0.25  0\n",
       "3         4   0.31   0.19     0.03   0.39  0.25  0\n",
       "4         5   0.45   0.22     0.03   0.79  0.28  0\n",
       "5         6   0.46   0.22     0.03   1.29  0.32  0\n",
       "6         7   0.01  -0.03     0.01   0.11  0.25  0\n",
       "7         8  -0.11  -0.12     0.03   0.15  0.32  0\n",
       "8         9   0.06  -0.11     0.04   0.41  0.29  0\n",
       "9        10   0.05  -0.09     0.05   0.25  0.34  0\n",
       "10       11   0.12  -0.11     0.04   0.46  0.31  0\n",
       "11       12  -0.04   0.27     0.05   0.59  0.21  0\n",
       "12       13  -0.04   0.25     0.03   0.33  0.21  0\n",
       "13       14   0.00   0.15     0.00   0.16  0.16  0\n",
       "14       15  -0.05   0.02     0.01   0.07  0.16  0\n",
       "15       16  -0.03  -0.01     0.02   0.10  0.18  0\n",
       "16       17  -0.03  -0.04     0.02   0.09  0.19  0\n",
       "17       18   0.02   0.05     0.05   0.55  0.07  0\n",
       "18       19   0.02   0.08     0.03   0.60  0.09  0\n",
       "19       20   0.03   0.11     0.04   0.79  0.10  0\n",
       "20       21   0.00   0.12     0.04   0.82  0.09  0\n",
       "21       22   0.04   0.14     0.02   0.63  0.12  0\n",
       "22       23  -0.05   0.15     0.04   0.89  0.15  0\n",
       "23       24  -0.01   0.14     0.04   0.68  0.11  0\n",
       "24       25   0.36   0.06     0.03   3.20  0.28  1\n",
       "25       26   0.07   0.11     0.04   0.04  0.12  1\n",
       "26       27  -0.04   0.31     0.03   0.59  0.09  0\n",
       "27       28   0.31  -0.09     0.02   0.55  0.33  0\n",
       "28       29   0.00   0.19     0.03   0.79  0.32  0\n",
       "29       30   0.00   0.11     0.02   0.63  0.21  0\n",
       "30       31   0.02   0.02     0.03   0.79  0.33  0\n",
       "31       32  -0.05   0.25     0.03   0.59  0.29  0\n",
       "32       33   0.12  -0.04     0.05   0.10  0.19  0\n",
       "33       34  -0.05   0.22     0.02   0.79  0.33  0\n",
       "34       35  -0.01  -0.09     0.01   0.25  0.16  0\n",
       "35       36   0.12   0.19     0.04   0.16  0.25  0\n",
       "36       37   0.04   0.11     0.03   0.96  0.21  0\n",
       "37       38   0.02  -0.01     0.00   0.96  0.25  0\n",
       "38       39  -0.04  -0.11     0.05   0.25  0.29  0\n",
       "39       40   0.00  -0.03     0.03   0.11  0.32  0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21553 entries, 0 to 21552\n",
      "Data columns (total 7 columns):\n",
      "Firm ID    21553 non-null int64\n",
      "WC/TA      21553 non-null float64\n",
      "RE/TA      21553 non-null float64\n",
      "EBIT/TA    21553 non-null float64\n",
      "ME/TL      21553 non-null float64\n",
      "S/TA       21553 non-null float64\n",
      "y          21553 non-null int64\n",
      "dtypes: float64(5), int64(2)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - CorporateID (numeric)\n",
    "\n",
    "2 - WC/TA: Working Capital (WC) divided by Total Assets (TA). All of these items are found in the balance\n",
    "sheet of the company(numeric)\n",
    "\n",
    "3 - RE/TA: Retained Earnings (RE) divided by Total Assets (TA). All of these items are found in the balance\n",
    "sheet of the company(numeric)\n",
    "\n",
    "4 - EBIT/TA: Earnings before interest and taxes (EBIT) divided by Total Assets (TA). All of these items are found in the balance sheet and income statement of the company(numeric)\n",
    "\n",
    "5 - ME/TL: Market Value of Equity (ME) divided by Total Liabilities (TL). Total Liabilities is found in the balance\n",
    "sheet of the company. The market value is given by the number of shares outstanding multiplied by the stock price. (numeric)\n",
    "\n",
    "6 - Sales/TA: Sales (S) divided by Total Assets (TA). All of these items are found in the balance sheet and income statement of the company(numeric)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict variable (desired target):\n",
    "\n",
    "y - Did the firm defaulted? (binary: '1','0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20000\n",
       "1     1553\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='y',data=data)\n",
    "plt.show()\n",
    "plt.savefig('count_plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m percentage of no default is\u001b[1m 92.79450656521135\n",
      "\u001b[1m percentage of default\u001b[1m 7.205493434788661\n"
     ]
    }
   ],
   "source": [
    "count_no_default = len(data[data['y']==0])\n",
    "count_default = len(data[data['y']==1])\n",
    "pct_of_no_default = count_no_default/(count_no_default+count_default)\n",
    "print(\"\\033[1m percentage of no default is\\033[1m\", pct_of_no_default*100)\n",
    "pct_of_default = count_default/(count_no_default+count_default)\n",
    "print(\"\\033[1m percentage of default\\033[1m\", pct_of_default*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classes are imbalanced, and the ratio of no-default to default instances is 93:7. Before we go ahead to balance the classes, letâ€™s do some more exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a sense of the numbers across the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Firm ID</th>\n",
       "      <th>WC/TA</th>\n",
       "      <th>RE/TA</th>\n",
       "      <th>EBIT/TA</th>\n",
       "      <th>ME/TL</th>\n",
       "      <th>S/TA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002.497600</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.103059</td>\n",
       "      <td>0.03206</td>\n",
       "      <td>0.535583</td>\n",
       "      <td>0.212753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20773.245976</td>\n",
       "      <td>0.217997</td>\n",
       "      <td>0.085396</td>\n",
       "      <td>0.03490</td>\n",
       "      <td>1.589981</td>\n",
       "      <td>0.199723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Firm ID     WC/TA     RE/TA  EBIT/TA     ME/TL      S/TA\n",
       "y                                                               \n",
       "0  10002.497600  0.113131  0.103059  0.03206  0.535583  0.212753\n",
       "1  20773.245976  0.217997  0.085396  0.03490  1.589981  0.199723"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('y').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Firm ID', 'WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA', 'y'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final=data\n",
    "data_final.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.drop(['Firm ID'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over-sampling using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our training data created, Iâ€™ll up-sample the no-subscription using the __SMOTE algorithm__ (Synthetic Minority Oversampling Technique). At a high level, SMOTE:\n",
    "\n",
    "1. Works by creating synthetic samples from the minor class (default) instead of creating copies.\n",
    "\n",
    "2. Randomly choosing one of the k-nearest-neighbors and using it to create a similar, but randomly tweaked, new observations.\n",
    "\n",
    "We are going to implement SMOTE in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_final.loc[:, data_final.columns != 'y']\n",
    "y = data_final.loc[:, data_final.columns == 'y']\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns\n",
    "os_data_X,os_data_y=os.fit_sample(X_train, y_train)\n",
    "os_data_X = pd.DataFrame(data=os_data_X,columns=columns )\n",
    "os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m length of oversampled data is 27996\n",
      "\u001b[1m Number of no default in oversampled data 13998\n",
      "\u001b[1m Number of default 13998\n",
      "\u001b[1m Proportion of no default data in oversampled data is  0.5\n",
      "\u001b[1m Proportion of default data in oversampled data is  0.5\n"
     ]
    }
   ],
   "source": [
    "# we can Check the numbers of our data\n",
    "print(\"\\033[1m length of oversampled data is\" ,len(os_data_X))\n",
    "print(\"\\033[1m Number of no default in oversampled data\",len(os_data_y[os_data_y['y']==0]))\n",
    "print(\"\\033[1m Number of default\",len(os_data_y[os_data_y['y']==1]))\n",
    "print(\"\\033[1m Proportion of no default data in oversampled data is \",len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "print(\"\\033[1m Proportion of default data in oversampled data is \",len(os_data_y[os_data_y['y']==1])/len(os_data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a perfect balanced data! You may have noticed that I over-sampled only on the training data, because by oversampling only on the training data, none of the information in the test data is being used to create synthetic observations, therefore, no information will bleed from test data into the model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recursive Feature Elimination (RFE)__ is based on the idea to repeatedly construct a model and choose either the best or worst performing feature, setting the feature aside and then repeating the process with the rest of the features. This process is applied until all features in the dataset are exhausted. The goal of RFE is to select features by recursively considering smaller and smaller sets of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "rfe = RFE(logreg, 20)\n",
    "rfe = rfe.fit(os_data_X, os_data_y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True]\n",
      "[1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WC/TA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RE/TA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EBIT/TA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ME/TL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S/TA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature  Importance\n",
       "0    WC/TA           1\n",
       "1    RE/TA           1\n",
       "2  EBIT/TA           1\n",
       "3    ME/TL           1\n",
       "4     S/TA           1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_X2 = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rfe.ranking_},)\n",
    "sf_X2.sort_values(by=['Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA']\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "cols=[]\n",
    "for i in range (0, len(sf_X2[\"Importance\"])):\n",
    "    if sf_X2[\"Importance\"][i] == 1:\n",
    "        cols.append(sf_X2[\"Feature\"][i])\n",
    "print(cols)\n",
    "print(len(cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Recursive Feature Elimination (RFE) has helped us select the following features: 'WC/TA', 'RE/TA', 'EBIT/TA', 'ME/TL', 'S/TA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[cols]\n",
    "y=y['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2542: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.149154\n",
      "         Iterations 8\n",
      "                         Results: Logit\n",
      "================================================================\n",
      "Model:              Logit            Pseudo R-squared: 0.424    \n",
      "Dependent Variable: y                AIC:              6441.4320\n",
      "Date:               2020-06-04 23:51 BIC:              6489.3016\n",
      "No. Observations:   21553            Log-Likelihood:   -3214.7  \n",
      "Df Model:           5                LL-Null:          -5580.6  \n",
      "Df Residuals:       21547            LLR p-value:      0.0000   \n",
      "Converged:          1.0000           Scale:            1.0000   \n",
      "No. Iterations:     8.0000                                      \n",
      "-----------------------------------------------------------------\n",
      "             Coef.   Std.Err.     z      P>|z|    [0.025   0.975]\n",
      "-----------------------------------------------------------------\n",
      "const       -6.1926    0.1651  -37.5035  0.0000  -6.5163  -5.8690\n",
      "WC/TA        2.3290    0.1614   14.4272  0.0000   2.0126   2.6454\n",
      "RE/TA       -1.0461    0.2802   -3.7334  0.0002  -1.5953  -0.4969\n",
      "EBIT/TA     20.6982    3.0061    6.8853  0.0000  14.8063  26.5901\n",
      "ME/TL        3.3731    0.0784   43.0259  0.0000   3.2195   3.5268\n",
      "S/TA        -1.6695    0.4226   -3.9501  0.0001  -2.4979  -0.8411\n",
      "================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "# Add a constant to the independent value\n",
    "X1 = sm.add_constant(X)\n",
    "logit_model=sm.Logit(y,X1)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the test set results and caculating the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression on test set: 0.96\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression on test set: {:.2f}'.format(lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute precision, recall, F-measure and support\n",
    "\n",
    "The precision is the ratio tp / (tp + fp) where tp is the number of true positives and fp the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "\n",
    "The recall is the ratio tp / (tp + fn) where tp is the number of true positives and fn the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "\n",
    "The F-beta score can be interpreted as a weighted harmonic mean of the precision and recall, where an F-beta score reaches its best value at 1 and worst score at 0.\n",
    "\n",
    "The F-beta score weights recall more than precision by a factor of beta. beta == 1.0 means recall and precision are equally important.\n",
    "\n",
    "The support is the number of occurrences of each class in y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      6002\n",
      "           1       1.00      0.51      0.67       464\n",
      "\n",
      "    accuracy                           0.96      6466\n",
      "   macro avg       0.98      0.75      0.83      6466\n",
      "weighted avg       0.97      0.96      0.96      6466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model: 96.47%\n",
      "Well, we got a classification rate of 96.47%\n",
      "\n",
      "Precision of logistic regression model: 100.00%\n",
      "Precision: Precision is about being precise, i.e., how precise your model is. In other words, we can\n",
      " say, when a model makes a prediction, how often it is correct. In our prediction case, when our\n",
      " logistic regression model predicted an applicant is going to accept a credit card, that\n",
      " applicant actually accepted 100.00% of the time.\n",
      "\n",
      "Recall of logistic regression model: 50.86%\n",
      "Recall: If there is an applicant who accepted a credit card present in the test set and our logistic\n",
      " regression can identify it 50.86% of the time.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#calculate Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy of logistic regression model:\", \"{:.2%}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "print(\"Well, we got a classification rate of\", \"{:.2%}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
    "#calculate Precision\n",
    "print(\"\\nPrecision of logistic regression model:\", \"{:.2%}\".format(metrics.precision_score(y_test, y_pred)))\n",
    "print(\"Precision: Precision is about being precise, i.e., how precise your model is. In other words, we can\\n say, when a model makes a prediction, how often it is correct. In our prediction case, when our\\n logistic regression model predicted an applicant is going to accept a credit card, that\\n applicant actually accepted\", \"{:.2%}\".format(metrics.precision_score(y_test, y_pred)) ,\"of the time.\")\n",
    "#calculate Recall\n",
    "print(\"\\nRecall of logistic regression model:\", \"{:.2%}\".format(metrics.recall_score(y_test, y_pred)))\n",
    "print(\"Recall: If there is an applicant who accepted a credit card present in the test set and our logistic\\n regression can identify it\", \"{:.2%}\".format(metrics.recall_score(y_test, y_pred)) ,\"of the time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6002    0]\n",
      " [ 228  236]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result is telling us that we have:  6238 correct predictions.\n",
      "The result is telling us that we have:  228 incorrect predictions.\n",
      "We have a total predictions of:  6466\n"
     ]
    }
   ],
   "source": [
    "print(\"The result is telling us that we have: \",(confusion_matrix[0,0]+confusion_matrix[1,1]),\"correct predictions.\")\n",
    "print(\"The result is telling us that we have: \",(confusion_matrix[0,1]+confusion_matrix[1,0]),\"incorrect predictions.\")\n",
    "print(\"We have a total predictions of: \",(confusion_matrix.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "lr_roc_auc = roc_auc_score(y_test, lr.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % lr_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-time Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the best way to use this model is assigning Default Probability for each firm, create segments, and build strategies on top of that. To get the default probability from our model, utilize the code block below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.128574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.187837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.304481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.004328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         PD\n",
       "0  0.128574\n",
       "1  0.187837\n",
       "2  0.084148\n",
       "3  0.017649\n",
       "4  0.079290\n",
       "5  0.304481\n",
       "6  0.004328\n",
       "7  0.003877\n",
       "8  0.013894\n",
       "9  0.007499"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['PD'] = lr.predict_proba(data[X_train.columns])[:,1]\n",
    "data[['PD']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('PD.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
